{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Gentle Start\n",
    "\n",
    "Basic notions in machine learning include the following elements.\n",
    "* The domain set is represented by $\\mathcal{X}$.\n",
    "* The label set is represented by $\\mathcal{Y}$ and, at the onset, we take $\\mathcal{Y} = \\{ 0, 1 \\}$.\n",
    "* The training data is given by $S = \\left\\{ (x_i, y_i) \\right\\}$, where each element in this set belongs to $\\mathcal{X} \\times \\mathcal{Y}$.\n",
    "\n",
    "\n",
    "## Task\n",
    "\n",
    "* The learner wishes to create a prediction rule by $h : \\mathcal{X} \\mapsto \\mathcal{Y}$. This function is also called a predictor, a hypothesis, or a classifier.\n",
    "* It is sometime useful to denote a (correct) labeling function $f : \\mathcal{X} \\mapsto \\mathcal{Y}$ such that $y_i = f(x_i)$ for all $i$.\n",
    "\n",
    "\n",
    "## Design Objective\n",
    "\n",
    "* The last component needed is a measure of success. A typical such criterion can be derived from the probability of classification error:\n",
    "\\begin{equation*}\n",
    "L_{(\\mathcal{D}, f)} (h)\n",
    "\\doteq \\Pr_{x \\sim \\mathcal{D}} (h(x) \\neq f(x))\n",
    "= \\mathcal{D} \\left( \\{ x : h(x) \\neq f(x) \\} \\right) .\n",
    "\\end{equation*}\n",
    "In general, the nomenclature $L_{(\\mathcal{D}, f)} (\\cdot)$ refers to a loss function and $\\mathcal{D}$ is the probability distribution underlying $\\mathcal{X}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1.a\n",
    "\n",
    "Let $\\mathcal{D}$ be a multivariate normal distribution with location parameter $\\boldsymbol{\\mu} = \\mathbf{0}$ and covariance matrix $\\boldsymbol{\\Sigma} = \\mathbf{I}$.\n",
    "Moreover, assume that the labeling function $f : \\mathcal{X} \\mapsto \\mathbf{Y}$ is given by\n",
    "\\begin{equation*}\n",
    "f(\\mathbf{x}) = \\operatorname{sign} \\left( \\langle \\mathbf{x} | \\mathbf{v} \\rangle \\right)\n",
    "\\end{equation*}\n",
    "where $\\mathbf{v}$ is a fixed vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 0\n",
    "sigma = 1\n",
    "fvector = np.random.normal(mu, sigma, (1,2))\n",
    "print('Label Vector: ' + str(fvector))\n",
    "X = np.random.normal(mu, sigma, (10,2))\n",
    "\n",
    "def labelfunction(x_i):\n",
    "    sign = np.sign(np.inner(x_i, fvector))\n",
    "    return sign\n",
    "\n",
    "XY_df = pd.DataFrame(X, columns=['pos1','pos2'])\n",
    "XY_df['Y'] = labelfunction(X)\n",
    "set1 = XY_df.loc[XY_df['Y'] > 0].as_matrix(['pos1','pos2'])\n",
    "set0 = XY_df.loc[XY_df['Y'] < 0].as_matrix(['pos1','pos2'])\n",
    "\n",
    "x, y = zip(*set1)\n",
    "plt.scatter(x, y, c='b')\n",
    "x, y = zip(*set0)\n",
    "plt.scatter(x, y, c='r')\n",
    "ax = plt.gca()\n",
    "ax.set_xlim([-4,4])\n",
    "ax.set_ylim([-4,4])\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empirical Risk Minimization (ERM)\n",
    "\n",
    "Given that only the training sample is available to the learner, it may be appealing to search for a solution that works well on $S$:\n",
    "\\begin{equation*}\n",
    "L_{S} (h) \\doteq \\frac{\\left| \\{ i \\in [m] : h(x_i) \\neq u_i \\} \\right|}{m} .\n",
    "\\end{equation*}\n",
    "The objective function is often referred to as the empirical error and empirical risk.\n",
    "Unfortunatly, ERM is prone to overfitting, a phenomenon where the hypothesis fits the training data well, but performs poorly in reality.\n",
    "\n",
    "\n",
    "## Inductive Bias\n",
    "\n",
    "A common strategy to prevent overfitting is to apply the ERM learning rule over a restricted hypothesis class $\\mathcal{H}$.\n",
    "The learner then uses the ERM rule to choose a predictor $h \\in \\mathcal{H}$, with the lowest possible error over $S$;\n",
    "\\begin{equation*}\n",
    "\\mathrm{ERM}_{\\mathcal{H}} (S) \\in \\operatorname{argmin}_{h \\in \\mathcal{H}} L_S (h) .\n",
    "\\end{equation*}\n",
    "Choosing a restricted hypothesis class can help protect against overfitting, but it may cause us a stronger inductive bias.\n",
    "\n",
    "\n",
    "## Assumptions\n",
    "\n",
    "**Realizability Assumption:** There exists $h^{\\star} \\in \\mathcal{H}$ such that $L_{(\\mathcal{D}, f)} (h^{\\star}) = 0$.\n",
    "Note that this assumption implies that $L_S(h^{\\star}) = 0$ almost surely.\n",
    "\n",
    "**IID Assumption:** The points in the training set $S$ are drawn independently according to the distribution $\\mathcal{D}$. Consequently, $S \\sim \\mathcal{D}^m$ where $m$ is the cardinality of $S$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1.b\n",
    "\n",
    "Let $\\mathcal{H}$ be the hypothesis class given by\n",
    "\\begin{equation*}\n",
    "h_w(\\mathbf{x}) = \\operatorname{sign} \\left( \\langle \\mathbf{x} | \\mathbf{w} \\rangle \\right)\n",
    "\\end{equation*}\n",
    "where $\\mathbf{w}$ is a fixed vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Bounds\n",
    "\n",
    "There is some probability that the sampled training data $S$ is nonrepresentative of the underlying distribution $\\mathcal{D}$, in which case $L_{(\\mathcal{D}, f)} (h_S)$ may feature bad performance.\n",
    "The probability of getting a nonrepresentative sample is denoted by $\\delta$, and $(1 âˆ’ \\delta)$ is call the confidence parameter of the prediction problem.\n",
    "\n",
    "Let $\\epsilon$ denote the accuracy parameter.\n",
    "We interpret the event $L_{(\\mathcal{D}, f)}(h_S) > \\epsilon$ as a failure of the learner, whereas the condition $L_{(\\mathcal{D}, f)}(h_S) \\leq \\epsilon$ is deemed an approximately correct predictor.\n",
    "We wish to bound\n",
    "\\begin{equation*}\n",
    "\\mathcal{D}^m \\left( \\left\\{ \\left. S \\right|_x : L_{(\\mathcal{D}, f)}(h_S) > \\epsilon \\right\\} \\right)\n",
    "\\end{equation*}\n",
    "Let $\\mathcal{H}_{\\mathrm{B}}$ be the set of bad hypothesis,\n",
    "\\begin{equation*}\n",
    "\\mathcal{H}_{\\mathrm{B}}\n",
    "= \\left\\{ h \\in \\mathcal{H} : L_{(\\mathcal{D}, f)}(h) > \\epsilon \\right\\} .\n",
    "\\end{equation*}\n",
    "Also, let\n",
    "\\begin{equation*}\n",
    "M = \\left\\{ \\left. S \\right|_x : \\exists h \\in \\mathcal{H}_{\\mathrm{B}}, L_S(h) = 0 \\right\\} .\n",
    "\\end{equation*}\n",
    "\n",
    "The event $L_{\\mathcal{D}, f}(h_S) > \\epsilon$ can only happen if for some $h \\in \\mathcal{H}_{\\mathrm{B}}$ we have $L_S (h) = 0$.\n",
    "In other words, this event will only happen if our sample is in the set of misleading samples, $M$,\n",
    "\\begin{equation*}\n",
    "\\left\\{ \\left. S \\right|_x :  L_{(\\mathcal{D}, f)}(h_S) > \\epsilon \\right\\} \\subseteq M.\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
